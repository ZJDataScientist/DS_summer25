---
title: "WebSraping-SQL"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo       = TRUE, 
                      fig.align  = "center",
                      fig.height = 3, fig.width = 4)
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
```

## Instructions

Complete the following exercises using the appropriate packages in R. Ensure that your solutions are optimized and use functional programming principles where applicable.

1.  Load the necessary libraries.
2.  Answer each question in separate R code chunks.
3.  Provide detailed explanations for your approach.
4.  Submit the rendered HTML file.

```{r}
  if (!require("pacman")) install.packages("pacman")

# Load contributed packages with pacman
pacman::p_load(pacman,rvest, dplyr, tidyverse, xml2,janitor, DBI, duckdb, nycflights13)
```

## WebScraping

### Problem 1:

Go to the following page [List of U.S. states and territories by population](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population) and select the table `State and territory rankings`.

1.  Make sure the name of columns and the first row is correct\
2.  Make sure the class of each column is correct\
3.  Replace `__` with `NA`

**Solution Strategy:** \
\
 1. Read the Wikipedia page

2.  Extract all tables with 'wikitable'
3.  Target the correct table by position
4.  Extract the <thead> rows for custom header handling
5.  Extract header text using html_text2() to avoid NA issues
6.  Combine multi-row headers keeping first column from header1, rest from header2
7.  Extract table body (the actual data rows)
8.  Assign clean column names
9.  Clean up "\_\_" & "-"and convert to NA
10. Convert Column Types:
11. View structure

```{r}


# Step 1: Read the Wikipedia page
url <- "https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population"
wiki_html <- read_html(url)

# Step 2: Extract all tables with class 'wikitable'
tables <- html_elements(wiki_html, ".wikitable")

# Step 3: Target the correct table by position 
target_table <- tables[[1]]

# Step 4: Extract the <thead> rows for custom header handling
header_rows <- html_elements(target_table, "thead tr")

# Step 5: Extract header text using html_text2() to avoid NA issues
header1 <- html_elements(header_rows[1], "th") %>% html_text2()
header2 <- html_elements(header_rows[2], "th") %>% html_text2()

# Step 6: Combine multi-row headers

full_headers <- c(header1[1], header2)

# Step 7: Extract table body (the actual data rows)
table_body <- html_element(target_table, "tbody") %>%
  html_table(header = FALSE)

# Step 8: Assign clean column names (temporary)
colnames(table_body) <- make_clean_names(full_headers)

# 8.1 Promote first row as column names
table_body <- row_to_names(table_body, row_number = 1)

# Clean column names again (now the real headers)
table_body <- clean_names(table_body)

# Step 9: Clean up "__" and "—" and convert to NA
table_body <- table_body %>%
  mutate(across(everything(), ~ na_if(., "__"))) %>%
  mutate(across(everything(), ~ na_if(., "—")))

# Step 10: Convert column types
table_body <- readr::type_convert(table_body)
```

Optional step I like to use is to display the link to the original source using gt:

```{r}

table_body %>%
  gt() %>%
  tab_caption("Table: U.S. States and Territories by Population") %>%
  tab_source_note(
    source_note = md("Source: [Wikipedia](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population)")
  )
```

\
To Solve this problem, we begin by scrapping the target Wikipedia page and identifying the correct table using CSS selector. Since the table has multiple row heads, we manually extract and combine them to construct clean column names. The table data is then read in without headers, and the combined headers are applied. We replace placeholders values like "\_\_" and "-" with NA to standardize missing data. The first row is promoted to become the column names, followed by cleaning and converting the column types to their appropriate formats using readr::type_convert(). This ensures the data is tidy and usable for further analysis. \
\
An optional step I like to use is to display the cleaned table using the gt package, which allows me to add a caption and include a clickable link to the original source for reference.
