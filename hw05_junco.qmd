---
title: "Exploring Joyful Language in Jane Austenâ€™s Emma using Tidytext"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo       = TRUE, 
                      fig.align  = "center",
                      fig.height = 3, fig.width = 4)
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
```

### **Instructions**

Complete the following exercises using the appropriate packages in R. Ensure that your solutions are optimized and use functional programming principles where applicable.

1.  Load the necessary libraries.
2.  Answer each question in separate R code chunks.
3.  Provide detailed explanations for your approach.
4.  Submit the rendered HTML file.

#### **Objective**:

Use the **`tidytext`** package and three different **sentiment lexicons** (`nrc`, `afinn`, `bing`) to explore **positive/joyful words** in *Emma* by Jane Austen. You will tokenize the text, apply sentiment filters, visualize frequent sentiment words using `ggplot2`, and create a word cloud.

### **Tasks**:

1.  **Data Preparation**

a\. Load the `austen_books()` dataset from the **`janeaustenr`** package.

```{r}
library(janeaustenr)
library(tidyverse)
library(dplyr)
library(stringr)
library(tibble)
library(tidyr)
library(tidytext)
library(textdata)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(ggrepel)
library(patchwork)
```

b\. Group by book and detect chapter boundaries using regex; and Create `linenumber` and `chapter` columns.

```{r}

austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(
      text, 
      regex("^chapter\\s+[\\divxlc]+", 
            ignore_case = TRUE
           )
      )),
    .before = text
  ) %>%
  ungroup() %>%
  select(book, chapter, linenumber, text) -> 
  chapter_boundaries
head(chapter_boundaries)
```

***The code processes Jane Austen's text by:***

-   Grouping the data by book title

-   Creating two new columns:

    -   Line number: assigns a sequential number to each line

    -   chapter: detects chapter headers using regex and assigns a chapter number using cumulative counting with cumsum()

-   The regex looks for lines that begin with the word "chapter" followed by a space and a Roman numeral or digit.

-   These new columns are inserted before the text column using .before = text.

-   The grouping is removed (ungroup()), and only relevant columns (book, chapter, linenumber, text) atr selected.

-   The final processed data is saved into an object called chapter_boundaries

***Regex Breakdown:***

-   \^chapter: matches lines that start with the word "chapter"

-   \\\\s+: matches one or more spaces after "chapter"

-   \[\\\\divxlc\] +: matches Roman numerals, handling lowercase, and could also allow digits depending on variation. It also assigns them as chapter boundaries.

Chapter boundaries refer to the starting points of new chapters (we're not trying to figure out where they end).

2.  **Tokenization**

-   Use `unnest_tokens()` to tokenize text into individual words.
-   Explain briefly **why we name the output column `word`** (include this as a comment in your script).

```{r}
## We name the output column 'word' because is the conventional tidytext function for sentiment analysis

chapter_boundaries %>% 
  unnest_tokens(word, text) %>%  ## Tokenize text into individual words
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words, by = "word") -> 
  tidy_author 
head(tidy_author)
```

***Code Explanation:***

-   We name the output column "word" in unnest_tokens(word,text) because that's the standard name that functions in tidytext. It makes later joins with sentiment lexicons and stop word list easier, since those also use "word" as the column name.

-   We use str_extract() to keep only alphabetic characters and apostrophes, removing punctuation or formating symbols. Then we remove common stop words (like "the", "and", "of") using anti_join(stop_words), which helps focus the analysis on meaningful words.

3.  **Sentiment Analysis**

-   Filter joy/positive words from **each** of the three sentiment lexicons:

    -   `nrc` (joy)

    ```{r}
    ## Filter word associated with "joy" sentiment
    nrc_joy <- get_sentiments("nrc") %>% 
      filter(sentiment == "joy")
    head(nrc_joy)
    ```

    -   `afinn` (positive scores â‰¥ 1)

    ```{r}
    ## numeric sentiment scores with score of 1 or higher (representing positive sentiment)
    afinn_positive <- get_sentiments("afinn") %>% 
      filter(value >= 1)
    head(afinn_positive)
    ```

    -   `bing` (positive)

    ```{r}
    ## retain only words labeled as "positive"
    bing_positive<- get_sentiments("bing") %>% 
      filter(sentiment == "positive")
    head(bing_positive)

    ```

    In this step, we extract positive or joyful words from the three most common lexicons. This preprocessing gives us three sentiment specific word lists that we'll use to explore sentiment within Jane Austen's Emma.

Join each with *Emma*'s text and:

-   Count word frequency.

-   Filter for frequently occurring words (`n > 50`).

    -   `nrc` (joy)

```{r}
## NRC 

emma_joy_words <- chapter_boundaries %>%
  filter(book == "Emma") %>%
  unnest_tokens(word, text) %>%
  inner_join(nrc_joy, by = "word") %>%
  count(word, sort = TRUE) %>%
  filter(n > 50) # Line filtering by frequency
head(emma_joy_words)
  
```

We previously filtered the NRC lexicon (nrc_joy) for words tagged as "joy", then joined it with the tonekized Emma text to count the most frequently joyful words. Words appearing more than 50 times were retained.

-   `bing` (positive)

```{r}
## bing 

emma_bing_words <- chapter_boundaries %>%
  filter(book == "Emma") %>%
  unnest_tokens(word, text) %>%
  inner_join(bing_positive, by = "word") %>%
  count(word, sort = TRUE) %>%
  filter(n > 50) # Line filtering by frequency
head(emma_bing_words)

```

The bing lexicon classifies words as either "positive" or "negative". We filtered (bing_positive) for "positive" words and joined with Emma to find the most used positive vocabulary.

-   `afinn` (positive scores â‰¥ 1)

```{r}
## afinn

emma_afinn_words <- chapter_boundaries %>%
  filter(book == "Emma") %>%
  unnest_tokens(word, text) %>%
  inner_join(afinn_positive, by = "word") %>%
  count(word, sort = TRUE) %>%
  filter(n > 50) # Line filtering by frequency
head(emma_afinn_words)

```

Afinn assigns numeric sentiment scores. We selected words with a score of 1 or more positive sentiments (afinn_positive) joined them with the text, and identified those that occurred frequently.

-   Visualize using a **bar chart** (`ggplot2`) and a **word cloud** (`wordcloud`).
-   Bar Chart

```{r}
## Bar Chart using bing - Top positive words (n > 50)

plot_bing <- ggplot(emma_bing_words, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "#1b9e77") +
  coord_flip() +
  labs(title = "Bing Lexicon", x = "Word", y = "Frequency") +
  theme_minimal()
plot_bing
```

```{r}
## Bar Chart using afinn 

plot_afinn <- ggplot(emma_afinn_words, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "#d95f02") +
  coord_flip() +
  labs(title = "afinn Lexicon", x = "Word", y = "Frequency") +
  theme_minimal()
plot_afinn
```

```{r}
## nrc (Joy)

plot_nrc <- ggplot(emma_joy_words, aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "#7570b3") +
  coord_flip() +
  labs(title = "NRC Joy Words", x = "Word", y = "Frequency") +
  theme_minimal()
plot_nrc
```

The plots above compare the most frequent positive/joyful sentiment words in Emma using three popular sentiment lexicons: bin, afinn, nrc. The bar charts show word frequencies.

-   Chatter plot

```{r}
emma_chatter <- chapter_boundaries %>%
  filter(book == "Emma") %>%
  unnest_tokens(word, text) %>%
  inner_join(emma_bing_words, by = "word") %>%
  count(word, sort = TRUE) %>%
  filter(n > 50) %>%  # ðŸ”„ THIS LINE FILTERS BY FREQUENCY
  mutate(proportion = n / sum(n)) %>%
  mutate(book = "Emma")


ggplot(emma_chatter, aes(x = book, y = proportion, label = word)) +
  geom_text_repel(
    segment.alpha = 0,
    aes(size = proportion, color = proportion),
    max.overlaps = 100,
  ) +
  scale_size_continuous(range = c(3, 7), guide = "none") +
  scale_color_viridis_c(option = "plasma", guide = "none") +
  theme_minimal() +
  ggtitle("Top Positive Words in 'Emma' by Proportion") +
  ylab("Proportion of Words") +
  xlab("")
```

To visualize the positive words in Emma, we created a "chatter plot". The analysis filtered for words that appeared more than 50 times and were classified as positive by the bing Lexicon. Each word is displayed with its size and color scaled according to its relative frequency. The use of geom_text_repel() ensured that labels do not overlap, providing a clear, uncluttered view of the most impactful positive terms in the novel. This visualization highlights the language tone and recurring positive themes present thought the book.

-   Word cloud

```{r}
emma_chatter %>%
  filter(n > 50) %>%
  with(wordcloud(
    words = word,
    freq = n,
    max.words = 50,
    scale = c(3, 0.8)  # Adjusts max and min font sizes
  ))

```

The world cloud highlights the top 50 most frequent positive words in Emma, sized by their frequency. Unlike the chatter plot, which shows proportional differences more precisely, the word cloud offers a quick, visual impressison of word prominence. To avoid overlap issues, the text size was scaled to ensure readability.
